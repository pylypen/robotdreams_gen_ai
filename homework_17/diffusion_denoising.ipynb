{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66b5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5fb65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "DATA_DIR = './data'\n",
    "CHECKPOINT_DIR = './checkpoints_diffusion'\n",
    "LOG_PATH = './logs/diffusion_log.csv'\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TIMESTEPS = 1000  # noise steps\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5922cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with noisy-clean pairs using random Gaussian noise\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_size=64):\n",
    "        self.image_paths = list(Path(root_dir).rglob(\"*.jpg\")) + list(Path(root_dir).rglob(\"*.png\"))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        x_start = self.transform(img)\n",
    "        return x_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6125055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding for timestep embedding\n",
    "def sinusoidal_embedding(n, d):\n",
    "    pe = torch.zeros(n, d)\n",
    "    position = torch.arange(0, n, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d, 2).float() * -(math.log(10000.0) / d))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91957638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic UNet block for noise prediction\n",
    "class DenoiseModel(nn.Module):\n",
    "    def __init__(self, img_channels=3, base_channels=64, time_dim=256):\n",
    "        super().__init__()\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(img_channels, base_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(base_channels, base_channels, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(base_channels, img_channels, 3, padding=1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.time_to_channel = nn.Linear(time_dim, base_channels)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        t = self.time_embed(t_emb)\n",
    "        t = self.time_to_channel(t).unsqueeze(2).unsqueeze(3)\n",
    "        x = self.act(self.conv1(x) + t)\n",
    "        x = self.act(self.conv2(x))\n",
    "        return self.conv3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a81a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduler and noise methods\n",
    "class Diffusion:\n",
    "    def __init__(self, timesteps=1000):\n",
    "        self.timesteps = timesteps\n",
    "        self.betas = torch.linspace(1e-4, 0.02, timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_hat = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        sqrt_alpha_hat = self.alpha_hat[t].sqrt().view(-1, 1, 1, 1).to(DEVICE)\n",
    "        sqrt_one_minus = (1 - self.alpha_hat[t]).sqrt().view(-1, 1, 1, 1).to(DEVICE)\n",
    "        return sqrt_alpha_hat * x_start + sqrt_one_minus * noise\n",
    "\n",
    "    def p_losses(self, model, x_start, t):\n",
    "        noise = torch.randn_like(x_start)\n",
    "        x_noisy = self.q_sample(x_start, t, noise)\n",
    "        t_emb = sinusoidal_embedding(t, 256).to(x_start.device)\n",
    "        predicted_noise = model(x_noisy, t_emb)\n",
    "        return nn.MSELoss()(predicted_noise, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6899d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSNR and SSIM for evaluation\n",
    "def psnr(img1, img2):\n",
    "    mse = nn.functional.mse_loss(img1, img2)\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "\n",
    "def ssim(img1, img2):\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    mu1 = nn.functional.avg_pool2d(img1, 3, 1, 1)\n",
    "    mu2 = nn.functional.avg_pool2d(img2, 3, 1, 1)\n",
    "    sigma1 = nn.functional.avg_pool2d(img1 * img1, 3, 1, 1) - mu1 ** 2\n",
    "    sigma2 = nn.functional.avg_pool2d(img2 * img2, 3, 1, 1) - mu2 ** 2\n",
    "    sigma12 = nn.functional.avg_pool2d(img1 * img2, 3, 1, 1) - mu1 * mu2\n",
    "    ssim_map = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / ((mu1 ** 2 + mu2 ** 2 + C1) * (sigma1 + sigma2 + C2))\n",
    "    return ssim_map.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc8b314",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow([epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, avg_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(elapsed)])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 39\u001b[0m     train()\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     21\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, TIMESTEPS, (x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),), device\u001b[38;5;241m=\u001b[39mDEVICE)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mp_losses(model, x, t)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m, in \u001b[0;36mDiffusion.p_losses\u001b[1;34m(self, model, x_start, t)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_losses\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, x_start, t):\n\u001b[0;32m     17\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_start)\n\u001b[1;32m---> 18\u001b[0m     x_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x_start, t, noise)\n\u001b[0;32m     19\u001b[0m     t_emb \u001b[38;5;241m=\u001b[39m sinusoidal_embedding(t, \u001b[38;5;241m256\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x_start\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     20\u001b[0m     predicted_noise \u001b[38;5;241m=\u001b[39m model(x_noisy, t_emb)\n",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m, in \u001b[0;36mDiffusion.q_sample\u001b[1;34m(self, x_start, t, noise)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_start)\n\u001b[1;32m---> 12\u001b[0m sqrt_alpha_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_hat[t]\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     13\u001b[0m sqrt_one_minus \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_hat[t])\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sqrt_alpha_hat \u001b[38;5;241m*\u001b[39m x_start \u001b[38;5;241m+\u001b[39m sqrt_one_minus \u001b[38;5;241m*\u001b[39m noise\n",
      "\u001b[1;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "def train():\n",
    "    dataset = FaceDataset(DATA_DIR, IMAGE_SIZE)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    model = DenoiseModel().to(DEVICE)\n",
    "    diffusion = Diffusion(timesteps=TIMESTEPS)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    if not os.path.exists(LOG_PATH):\n",
    "        with open(LOG_PATH, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Epoch\", \"Loss\", \"PSNR\", \"SSIM\", \"Time\"])\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        psnrs, ssims = [], []\n",
    "        start_time = time.time()\n",
    "        for x in dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            t = torch.randint(0, TIMESTEPS, (x.size(0),), device=DEVICE).long()\n",
    "            loss = diffusion.p_losses(model, x, t)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        avg_loss = np.mean(losses)\n",
    "        elapsed = timedelta(seconds=int(time.time() - start_time))\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Time: {elapsed}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"{CHECKPOINT_DIR}/model_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        with open(LOG_PATH, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([epoch+1, avg_loss, \"-\", \"-\", str(elapsed)])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8181ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
